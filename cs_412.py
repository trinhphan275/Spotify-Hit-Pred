# -*- coding: utf-8 -*-
"""CS 412.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1SXPIog6wiGTmmG5VuJc8vuAxrxfPwz8w

## Importing libraries
"""

import time
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split, StratifiedKFold, cross_val_score
from sklearn.model_selection import cross_val_predict
from sklearn.neighbors import KNeighborsClassifier
from sklearn.ensemble import RandomForestClassifier
from sklearn.linear_model import LogisticRegression
from sklearn.neural_network import MLPClassifier
from sklearn.metrics import classification_report, confusion_matrix, accuracy_score, f1_score
from sklearn.compose import ColumnTransformer
from sklearn.preprocessing import StandardScaler, OneHotEncoder
from sklearn.pipeline import make_pipeline
from sklearn.svm import SVC
!pip install memory_profiler
from memory_profiler import memory_usage

# Load and prepare the data
def load_data(file_path):
    import pandas as pd

    data = pd.read_csv(file_path, encoding='latin1')
    data.head()
    data.describe()

    return data

# Adjust the file_path to the actual location of your dataset
file_path = 'dataset.csv'
df = load_data(file_path)

# Count of songs per artist
df_artists = df.groupby('artists').size().sort_values(ascending=False)

# Count of songs per genre
df_genre = df.groupby('track_genre').size().sort_values(ascending=False)

# Print the results
print("Songs per artist:")
print(df_artists)

print("\nSongs per genre:")
print(df_genre)


def prep_data(data):
    data.isna().sum()
    features_with_nan=[feature for feature in data.columns if data[feature].isna().sum()>0]
    features_with_nan
    for feature in features_with_nan:
      print('Number of missing value in {}: {}'.format(feature,np.round(data[feature].isna().sum())))

    data=data.dropna()
    data=data.drop_duplicates()
    data.drop(['Unnamed: 0', 'track_id', 'artists', 'album_name', 'track_name'], axis=1, inplace = True)

    print(f'number of duplicate rows: {data.duplicated().sum()}\nnumber of null values:\n{data.isna().sum()}')

    data['is_hit'] = data['popularity'].apply(lambda x: 1 if x > 50 else 0)

    features = ['duration_ms', 'explicit', 'danceability', 'energy', 'key', 'loudness', 'mode',
            'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo', 'time_signature']


    # Preprocessing for numeric and categorical features
    numerical_features = ['duration_ms', 'danceability', 'energy', 'loudness',
                          'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']
    categorical_features = ['explicit', 'mode', 'key', 'time_signature']
    X = data[numerical_features + categorical_features]
    y = data['is_hit']

    return data, X, y

df, X, y = prep_data(df)


# Check the output
df.isna().sum()
df.info()

# Define Numerical and Categorical Features
numerical_features = ['duration_ms', 'danceability', 'energy', 'loudness',
                      'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']
categorical_features = ['mode', 'key']

import matplotlib.pyplot as plt
import seaborn as sns
import pandas as pd

# Visualize distributions of numerical features
def visualize_numerical_features(data):
    numerical_features = ['duration_ms', 'danceability', 'energy', 'loudness',
                      'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']

    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(18, 12))
    axes = axes.flatten()

    for i, feature in enumerate(numerical_features):
        sns.histplot(data[feature], ax=axes[i], kde=True)
        axes[i].set_title(f'Distribution of {feature}')
        axes[i].set_xlabel(feature)

    plt.tight_layout()
    plt.show()

# Visualize relationships between numerical features and target variable
def visualize_numerical_target_relationship(data, target):
    numerical_features = ['duration_ms', 'danceability', 'energy', 'loudness',
                          'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']

    fig, axes = plt.subplots(nrows=3, ncols=4, figsize=(18, 12))
    axes = axes.flatten()

    for i, feature in enumerate(numerical_features):
        sns.scatterplot(x=feature, y=target, data=data, ax=axes[i])
        axes[i].set_title(f'{feature} vs {target}')
        axes[i].set_xlabel(feature)
        axes[i].set_ylabel(target)

    plt.tight_layout()
    plt.show()

# Visualize relationships between categorical features and target variable
def visualize_categorical_target_relationship(data, target):
    categorical_features = ['explicit', 'mode', 'key', 'time_signature']

    for feature in categorical_features:
        plt.figure(figsize=(8, 6))
        sns.barplot(x=feature, y=target, data=data)
        plt.title(f'{feature} vs {target}')
        plt.xlabel(feature)
        plt.ylabel(target)
        plt.show()

# Call visualization functions
visualize_numerical_features(df)
visualize_numerical_target_relationship(df, 'is_hit')
visualize_categorical_target_relationship(df, 'is_hit')

features = ['duration_ms', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']
for feature in features:
    plt.figure(figsize=(10, 5))
    sns.histplot(data=df, x=feature, hue='is_hit', kde=True)
    plt.title(f'Distribution of {feature} by Hit Status')
    plt.show()

corr_matrix = df[numerical_features + ['popularity'] + ['is_hit']].corr()
plt.figure(figsize=(12, 10))
sns.heatmap(corr_matrix, annot=True, fmt='.2f', cmap='coolwarm')
plt.title('Correlation Heatmap')
plt.show()

"""- **danceability_%** and **valence_%** have moderate positive correlations with **energy_%**, suggesting that songs which are more danceable and have a *higher valence (positivity) are often more energetic.*

- **acousticness_%** has a strong negative correlation with **energy_%**, which is displayed as a dark blue square, indicating that songs with **higher acousticness tend to have lower energy and vice versa**.
"""

categorical_features = ['explicit', 'mode', 'key', 'time_signature']
for feature in categorical_features:
    plt.figure(figsize=(10, 5))
    sns.countplot(x=feature, hue='is_hit', data=df)
    plt.title(f'Count of Hits and Non-Hits by {feature}')
    plt.show()

from sklearn.tree import DecisionTreeClassifier
import matplotlib.pyplot as plt

from sklearn.preprocessing import StandardScaler, LabelEncoder

# Scale numerical features
scaler = StandardScaler()
scaled_numerical = scaler.fit_transform(df[numerical_features])
scaled_df = pd.DataFrame(scaled_numerical, columns=numerical_features)

# Encode categorical features
encoder = LabelEncoder()
for feature in categorical_features:
    df[feature] = encoder.fit_transform(df[feature])

# Concatenate scaled numerical features, encoded categorical features, and target variable
df_processed = pd.concat([df[categorical_features], scaled_df, df['is_hit']], axis=1)
# Drop rows with missing values
df_processed.dropna(inplace=True)


# Separate features (X) and target variable (y)
X = df_processed.drop(columns=['is_hit'], axis=1)
y = df_processed['is_hit']

# Display the processed data
print("Processed Data:")
print(df_processed.head())
print("\nFeatures (X):")
print(X.head())
print("\nTarget Variable (y):")
print(y.head())


X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state = 0)

dt = DecisionTreeClassifier(random_state=1234)
dt.fit(X_train, y_train)

from sklearn.metrics import confusion_matrix, precision_score, recall_score, f1_score, accuracy_score

y_train_preddt = dt.predict(X_train)
y_test_preddt = dt.predict(X_test)

conf_matrix = confusion_matrix(y_true=y_test, y_pred=y_test_preddt)
#
# Print the confusion matrix using Matplotlib
#
fig, ax = plt.subplots(figsize=(5, 5))
ax.matshow(conf_matrix, cmap=plt.cm.Oranges, alpha=0.3)
for i in range(conf_matrix.shape[0]):
    for j in range(conf_matrix.shape[1]):
        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')

plt.xlabel('Predictions', fontsize=18)
plt.ylabel('Actuals', fontsize=18)
plt.title('Confusion Matrix', fontsize=18)
plt.show()

conf_matrix

print("Accuracy: ", (conf_matrix[0,0]+conf_matrix[1,1])/(conf_matrix[0,0]+conf_matrix[1,1]+conf_matrix[0,1]+conf_matrix[1,0]) )
print("Precision: ", (conf_matrix[0,0])/(conf_matrix[0,0]+conf_matrix[0,1]) )
print("Recall: ", (conf_matrix[0,0])/(conf_matrix[0,0]+conf_matrix[1,0]) )

# Preprocessing for numeric and categorical features
numerical_features = ['duration_ms', 'danceability', 'energy', 'loudness',
                          'speechiness', 'acousticness', 'instrumentalness', 'liveness', 'valence', 'tempo']
categorical_features = ['explicit', 'mode', 'key']

preprocessor = ColumnTransformer(
    transformers=[
        ('num', StandardScaler(), numerical_features),
        ('cat', OneHotEncoder(), categorical_features)
    ])

# Define models including SVM
models = {
    'KNN': KNeighborsClassifier(n_neighbors=5),
    'Logistic Regression': LogisticRegression(max_iter=5000),
    'Random Forest': RandomForestClassifier(random_state=42),
    'Neural Network': MLPClassifier(max_iter=1000, random_state=42),
    'SVM': SVC(kernel='linear')  # or 'rbf' for non-linear problems
}

# Set up 5-fold stratified cross-validation
cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)

# Perform training and evaluation
# for name, model in models.items():
#     pipeline = make_pipeline(preprocessor, model)
#     cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')
#     print(f"{name} Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})")

model_metrics = {}
for name, model in models.items():
    pipeline = make_pipeline(preprocessor, model)

    # Record the current time before training
    start_time = time.time()

    # Get memory usage before training
    mem_usage_before = memory_usage(-1, interval=0.1, timeout=1)

    # Perform the cross-validation
    cv_scores = cross_val_score(pipeline, X, y, cv=cv, scoring='accuracy')

    # Record the current time after training and calculate the elapsed time
    elapsed_time = time.time() - start_time

    # Get memory usage after training
    mem_usage_after = memory_usage(-1, interval=0.1, timeout=1)
    memory_used = max(mem_usage_after) - mem_usage_before[0]  # Max memory used during the cross-val

    # Print the accuracy and other metrics
    print(f"{name} Accuracy: {np.mean(cv_scores):.4f} (+/- {np.std(cv_scores):.4f})")
    print(f"{name} Training Time: {elapsed_time:.4f} seconds")
    print(f"{name} Memory Consumption: {memory_used:.4f} MiB")

    # Store the metrics in the dictionary
    model_metrics[name] = {
        'Accuracy': np.mean(cv_scores),
        'Training Time': elapsed_time,
        'Memory Consumption': memory_used
    }

# Get predictions for each fold of the cross-validation
y_pred = cross_val_predict(pipeline, X, y, cv=cv)

# Calculate metrics
print("Accuracy:", accuracy_score(y, y_pred))
print("F1 Score:", f1_score(y, y_pred, average='weighted'))
print("\nClassification Report:\n", classification_report(y, y_pred))

# Compute and display the confusion matrix
cm = confusion_matrix(y, y_pred)
plt.figure(figsize=(8, 6))
sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=['Non-Hit', 'Hit'], yticklabels=['Non-Hit', 'Hit'])
plt.ylabel('Actual Label')
plt.xlabel('Predicted Label')
plt.title('Confusion Matrix')
plt.show()
